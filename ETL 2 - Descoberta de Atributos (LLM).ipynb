{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOx9fsRKr30svwwcyK9vVan",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mateus-miguel/case-dadosfera/blob/main/ETL%202%20-%20Descoberta%20de%20Atributos%20(LLM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install boto3"
      ],
      "metadata": {
        "id": "JXI61xi6w9rJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nul17WjhJUEe",
        "outputId": "3afb4de6-879c-4a40-eb2c-3dbab66164b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'docid': 1657, 'title': \"Men's 3/4 Comression Pants Running Tights Sport Basketball Active Leggings 2 Pack\", 'text': \"Product Description Men's Compression 3/4 Pants for Sports Pants Features The material is 84% Polyester& 16% Spandex 2 peices of pants in one package for you to own High compression fit for support and reduced muscle vibration when doing sports Quick-dry, breathable fabric wicks sweat away keeps you stay cool and comfort 4-Way-Stretch Compression Pants offer greater range of movement with elastic waistband provides snug fit Suitable for many active sports Basketball Football Running Cycling \"}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import boto3\n",
        "import json\n",
        "import random\n",
        "\n",
        "# Chaves de acesso\n",
        "\n",
        "# Geramos um cliente S3 após definir as chaves de acesso do user IAM\n",
        "s3 = boto3.client('s3')\n",
        "\n",
        "# Requisitamos o arquivo JSON de produtos/schema do bucket S3 desejado, onde type(obj) = dict\n",
        "bucket = 'dadosfera-products-raw'\n",
        "file_json = 'products_clean_1000rows.json'\n",
        "\n",
        "# Abrindo o arquivo JSON a ser utilizado para descobrir atributos no LLM\n",
        "obj = s3.get_object(\n",
        "    Bucket=bucket,\n",
        "    Key=file_json\n",
        ")\n",
        "\n",
        "data = json.loads(obj[\"Body\"].read())\n",
        "\n",
        "# Abrindo arquivo sem usar S3, arquivo local no Colab\n",
        "# with open(file_json, 'r', encoding='utf-8') as f:\n",
        "#   data = json.load(f)\n",
        "\n",
        "# 1. Amostragem aleatória de k produtos entre o total do arquivo (p.ex. k = 100 entre 1000 linhas de produtos)\n",
        "sample = random.sample(data, k=1000)\n",
        "\n",
        "print(sample[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Função que gera o prompt baseado num sample aleatório de tamanho k produtos do arquivo JSON\n",
        "def build_prompt(products):\n",
        "  examples = []\n",
        "  for i, p in enumerate(products, 1):\n",
        "    examples.append(\n",
        "        f\"{i}. Title: {p['title']}\\n\"\n",
        "        f\"Description: {p['text']}\"\n",
        "    )\n",
        "\n",
        "    return f\"\"\"\n",
        "      You are analyzing a small dataset of product listings.\n",
        "\n",
        "      Your task:\n",
        "      - Propose a compact set of reusable general product attributes.\n",
        "      - Attributes must be applicable to MANY products (clothing, electronics, beauty, house, etc).\n",
        "      - Always use as initial attributes: category (clothing, electronics etc), material (str), color (list), size (list).\n",
        "      - Use enum (NOT list) and boolean.\n",
        "      - Avoid rare, cosmetic, or overly specific details.\n",
        "      - Do NOT include niche-specific attributes.\n",
        "      - Do NOT extract per-product values.\n",
        "\n",
        "      Only suggest attributes that:\n",
        "      - Apply to at least 30–40% of products across multiple unrelated categories\n",
        "      - Have HIGH frequency across the dataset.\n",
        "      - Are NOT specific to cosmetics, electronics, clothing, skincare, beauty, or personal care\n",
        "      - Can be reused across an entire e-commerce catalog\n",
        "\n",
        "      For each suggested attribute, provide:\n",
        "      - attribute_name (snake_case)\n",
        "      - attribute_type (boolean | enum | string)\n",
        "      - short description\n",
        "      - estimated_frequency (high / medium / low)\n",
        "      - Don't use `` for the values\n",
        "\n",
        "      After giving all attributes, give all the product categories found and for the first product make a JSON format with the keys being the found attributes and the values selected from the product title/text.\n",
        "\n",
        "      Dataset:\n",
        "      {chr(10).join(examples)}\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "rdFguIxOMvWH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# 3. Construir prompt\n",
        "prompt = build_prompt(sample)\n",
        "\n",
        "# 4. Criar client OpenAI\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "# 5. Chamar o modelo\n",
        "response = client.chat.completions.create(\n",
        "    model='gpt-4o-mini',\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    temperature=0.2\n",
        ")\n",
        "\n",
        "# 6. Ler resposta\n",
        "suggestions = response.choices[0].message.content\n",
        "print(suggestions)"
      ],
      "metadata": {
        "id": "CldOUHMLK8OI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Com base na resposta, definir um schema.json com atributos de alta/média frequência\n",
        "import re\n",
        "\n",
        "# Regex para capturar attribute_name e attribute_type\n",
        "pattern = r\"\\*\\*attribute_name\\*\\*:\\s*(\\w+)[\\s\\S]*?\\*\\*attribute_type\\*\\*:\\s*(\\w+)[\\s\\S]*?\\*\\*short_description\\*\\*:\\s*([^\\n\\r]+)\"\n",
        "\n",
        "text = suggestions\n",
        "matches = re.findall(pattern, text) # lista de tuples [(,), (,), ...]\n",
        "print(matches)\n",
        "\n",
        "# Limpando espaços finais nas descrições com .rstrip()\n",
        "matches_clean = []\n",
        "\n",
        "for match in matches:\n",
        "  match = list(match)\n",
        "  match[2] = match[2].rstrip()\n",
        "  match = tuple(match)\n",
        "  matches_clean.append(match)\n",
        "\n",
        "# Mapeando a forma dos tipos na saída da LLM para formato de dados no Python\n",
        "type_mapping = {\n",
        "    \"boolean\": \"bool\",\n",
        "    \"string\": \"str\",\n",
        "    \"enum\": \"list\",\n",
        "    \"list\": \"list\"\n",
        "}\n",
        "\n",
        "# Dicionário do schema a ser criado\n",
        "schema = {\n",
        "    'attributes': [\n",
        "        {\n",
        "            'name': 'docid',\n",
        "            'type': 'int',\n",
        "            'description': 'document ID for product'\n",
        "        },\n",
        "        {\n",
        "            'name': 'title',\n",
        "            'type': 'str',\n",
        "            'description': 'Name of product'\n",
        "        },\n",
        "        {\n",
        "            'name': 'text',\n",
        "            'type': 'str',\n",
        "            'description': 'Description for product'\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Após achar os matches do Regex na saída do LLM, os atributos, seus tipos e descrições são colocados no schema\n",
        "for name, attr_type, description in matches_clean:\n",
        "  schema['attributes'].append({\n",
        "      'name': name,\n",
        "      'type': type_mapping.get(attr_type.lower(), str),\n",
        "      'description': description\n",
        "  })\n",
        "\n",
        "# Guardando schema.json no bucket S3\n",
        "s3.put_object(\n",
        "    Bucket=bucket,\n",
        "    Key='schema_v2.json',\n",
        "    Body=json.dumps(schema, ensure_ascii=False).encode('utf-8')\n",
        ")\n",
        "\n",
        "# Output do schema como JSON localmente no Colab\n",
        "# with open('schema.json', 'w', encoding='utf-8') as f:\n",
        "#   json.dump(schema, f, ensure_ascii=False, indent=2)"
      ],
      "metadata": {
        "id": "SuAdsMY-WKm8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}