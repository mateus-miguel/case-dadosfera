{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3aBQ4f37198U7dsa83Avh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mateus-miguel/case-dadosfera/blob/main/ETL%201%20-%20Limpeza.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install boto3"
      ],
      "metadata": {
        "id": "7LEM6lEh6sAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Formato JSONL raw inicial ---\n",
        "# {'docid': int, 'title': str, 'text': str}\n",
        "# { ... }\n",
        "# { ... }\n",
        "\n",
        "# Ou seja, não é válido como JSON ao todo [{}, {}, ...] nem tem vírgulas, só é formado por vários JSON empilhados a cada linha."
      ],
      "metadata": {
        "id": "asYO-2MA71WP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTtn5rYMuGQH",
        "outputId": "6bf2a3ac-4207-42ec-93a7-2649b6c1a252"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'docid': 1, 'title': 'FYY Leather Case with Mirror for Samsung Galaxy S8 Plus, Leather Wallet Flip Folio Case with Mirror and Wrist Strap for Samsung Galaxy S8 Plus Black', 'text': 'Product Description Premium PU Leather Top quality. Made with Premium PU Leather. Receiver design. Accurate cut-out for receiver. Convenient to Answer the phone without open the case. Hand strap makes it easy to carry around. RFID Technique RFID Technique: Radio Frequency Identification technology, through radio signals to identify specific targets and to read and copy electronic data. Most Credit Cards, Debit Cards, ID Cards are set-in the RFID chip, the RFID reader can easily read the cards information within 10 feet(about 3m) without touching them. This case is designed to protect your cards information from stealing with blocking material of RFID shielding technology. 100% Handmade 100% Handmade. Perfect craftmanship and reinforced stitching makes it even more durable. Sleek, practical and elegant with a variety of dashing colors. Multiple Functions Card slots are designed for you to put your photo, debit card, credit card or ID card while on the go. Unique design. Cosmetic Mirror inside made for your makeup and beauty. Perfect Viewing Angle. Kickstand function is convenient for movie-watching or video-chatting. Space amplification, convenient to unlock. Kickstand function is convenient for movie-watching or video-chatting. '}\n",
            "Total de linhas do JSONL: 1118658\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import boto3\n",
        "import json\n",
        "\n",
        "# Chaves de acesso AWS\n",
        "\n",
        "\n",
        "# Locais do Bucket e File dentro da AWS S3\n",
        "dados = []\n",
        "bucket = 'dadosfera-datalake'\n",
        "file_jsonl = 'bronze/products_raw.jsonl'\n",
        "\n",
        "s3 = boto3.client('s3')\n",
        "\n",
        "obj = s3.get_object(\n",
        "    Bucket=bucket,\n",
        "    Key=file_jsonl\n",
        ")\n",
        "\n",
        "dados = []\n",
        "\n",
        "for line in obj[\"Body\"].iter_lines():\n",
        "  if line: # pula linhas vazias\n",
        "    dados.append(json.loads(line))\n",
        "\n",
        "# Não funciona pois é JSONL não JSON\n",
        "# data = json.loads(obj[\"Body\"].read())\n",
        "\n",
        "len_total = len(dados)\n",
        "print(dados[0])\n",
        "print(f'Total de linhas do JSONL: {len_total}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- LIMPEZA DE DADOS FALTANTES ---\n",
        "# Alguns produtos não têm title ou text (empty string), ou ambos, nesse caso são filtrados (removidos)\n",
        "# P.ex. docid: 5, 10, 13, 21, 39, 63, 77, 87, 99 não têm 'text', já docid: 65, 66, 97 não têm ambos 'title' e 'text'\n",
        "\n",
        "dados = [item for item in dados if item['title'] != '' and item['text'] != '']\n",
        "\n",
        "print(f'Total de produtos após filtro de nulos: {len(dados)}')\n",
        "print(f'Porcentagem de produtos nulos: {(1 - len(dados) / len_total) * 100 :.2f} %')\n",
        "\n",
        "# Normalizando outros objetos como aspas tipográficas “, ”, ‘, ’ pelas aspas comuns e –, • por string vazia\n",
        "def normalize(text: str) -> str:\n",
        "  replacements = {\n",
        "      \"“\": '\"', \"”\": '\"', \"‘\": \"'\", \"’\": \"'\", \"´\": \"'\", \"｀\": \"'\",\n",
        "      \"–\": \" \", \"—\": \" \", \"•\": \" \", \"*\": \" \", \"➤\": \" \", \"✔\": \" \", \"™\": \" \", \"®\": \" \",\n",
        "      \"Previous page\": \" \", \"Next page\": \" \", \"Product Description\": \" \", \"Read more\": \" \", \"From the manufacturer\": \" \"\n",
        "  }\n",
        "\n",
        "  for old, new in replacements.items():\n",
        "    text = text.replace(old, new)\n",
        "\n",
        "  return text\n",
        "\n",
        "changed = 0\n",
        "unchanged = 0\n",
        "\n",
        "for item in dados:\n",
        "  text = item.get('text')\n",
        "\n",
        "  normalized = normalize(item['text'])\n",
        "\n",
        "  if normalized != text:\n",
        "    changed += 1\n",
        "    item['text'] = normalized\n",
        "  else:\n",
        "    unchanged += 1\n",
        "\n",
        "print(f\"Descrições alteradas: {changed}\")\n",
        "print(f\"Descrições não alteradas: {unchanged}\")\n",
        "# 286214 descrições alteradas com essa normalização, cerca de 31.96%\n",
        "\n",
        "# Filtrando para apenas 100k produtos iniciais (mínimo do case)\n",
        "linhas = 100000\n",
        "dados_reduced = dados[0:linhas]\n",
        "\n",
        "# Colocando o novo arquivo limpo no bucket silver do bucket S3\n",
        "s3.put_object(\n",
        "    Bucket=bucket,\n",
        "    Key=f'silver/products_clean_{linhas}rows.json',\n",
        "    Body=json.dumps(dados_reduced, ensure_ascii=False).encode('utf-8')\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOdSDk30BjwR",
        "outputId": "c9e5b029-0263-4aab-b513-30df533dab9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de produtos após filtro de nulos: 895673\n",
            "Porcentagem de produtos nulos: 19.93 %\n",
            "Descrições alteradas: 0\n",
            "Descrições não alteradas: 895673\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ResponseMetadata': {'RequestId': 'C7HAJQTTP06NGFHY',\n",
              "  'HostId': 'IRvSmblV1Ddscg+Kb+EkcndQlaI8ete1FUc1fOo7bG3CHUT4sEjdDVT/Rpn70gCq+LQgU6WEGZU=',\n",
              "  'HTTPStatusCode': 200,\n",
              "  'HTTPHeaders': {'x-amz-id-2': 'IRvSmblV1Ddscg+Kb+EkcndQlaI8ete1FUc1fOo7bG3CHUT4sEjdDVT/Rpn70gCq+LQgU6WEGZU=',\n",
              "   'x-amz-request-id': 'C7HAJQTTP06NGFHY',\n",
              "   'date': 'Fri, 16 Jan 2026 15:53:19 GMT',\n",
              "   'x-amz-server-side-encryption': 'AES256',\n",
              "   'etag': '\"5f2918346e3c0c5e38a31fba58b30033\"',\n",
              "   'x-amz-checksum-crc32': 'FRMiRw==',\n",
              "   'x-amz-checksum-type': 'FULL_OBJECT',\n",
              "   'content-length': '0',\n",
              "   'server': 'AmazonS3'},\n",
              "  'RetryAttempts': 0},\n",
              " 'ETag': '\"5f2918346e3c0c5e38a31fba58b30033\"',\n",
              " 'ChecksumCRC32': 'FRMiRw==',\n",
              " 'ChecksumType': 'FULL_OBJECT',\n",
              " 'ServerSideEncryption': 'AES256'}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- BLOCO DE TESTE PARA ARQUIVO JSONL LOCAL ---\n",
        "\n",
        "arquivo = './products_raw.jsonl'\n",
        "\n",
        "# Contando total de linhas/produtos dentro do arquivo\n",
        "with open(arquivo, 'r', encoding='utf-8') as f:\n",
        "  total_linhas = sum(1 for _ in f)\n",
        "\n",
        "print(total_linhas)\n",
        "\n",
        "# Convertendo o arquivo JSONL ou TXT em um arquivo com todos os JSON dos produtos\n",
        "with open(arquivo, 'r', encoding='utf-8') as f:\n",
        "  for i, linha in enumerate(f, start=1):\n",
        "    linha = linha.strip() # tira \\n de nova linha\n",
        "    if not linha: # se não for vazia\n",
        "      continue\n",
        "\n",
        "    try:\n",
        "      obj = json.loads(linha)\n",
        "      dados.append(obj)\n",
        "\n",
        "    # Alguma ou algums linhas do JSONL geram um erro JSONDecodeError talvez por falta de fechar aspas \"\", então temos que tratar o erro try/except\n",
        "    except json.JSONDecodeError as e:\n",
        "      print(f'Erro na linha {i}: {e}')\n",
        "      print(linha[:300])\n",
        "      break\n",
        "\n",
        "# Limpeza de dados pois algumas linhas têm title ou text vazios (ou ambos)\n",
        "dados = [doc for doc in dados if doc['title'] != '' and doc['text'] != ''] # filtrado\n",
        "print(len(dados)) # total de produtos após filtro de nulos\n",
        "\n",
        "novos_dados = dados[0:100000]\n",
        "\n",
        "# Gerar um único JSON de saída com todos os produtos cadastrados\n",
        "with open('products_jsonl_1000.json', 'w', encoding='utf-8') as f:\n",
        "  json.dump(novos_dados, f, ensure_ascii=False, indent=2)"
      ],
      "metadata": {
        "id": "NuhHGoQA8QTu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}